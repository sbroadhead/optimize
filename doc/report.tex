\documentclass{report}
\usepackage[margin=1.25in]{geometry}
\usepackage[sc]{mathpazo}
\linespread{1.05}
\usepackage[T1]{fontenc}

\usepackage{nicefrac}
\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}
\title{Computing a Feasible Trajectory Through an Obstacle Field Using Nonlinear Constrained Optimization}
\author{
    Simon Broadhead\\
    Jeremy Ciesinski\\
    J.D. Cumpson\\
    Craig Skelsey\\
    Peter Smyth\\
    Junaid Syed\\
    Subramanian Venkatesan
}
\maketitle

%%%%%
\begin{abstract}
Abstract goes here
\end{abstract}

%%%%%
\chapter{Problem Overview}
\section{A Pathfinding Problem}
Pathfinding is a very important topic in the field of Computer Science.
Generally, when we talk about pathfinding algorithms, we talk about
algorithms to find the optimal path (for some objective function) through
a graph from a source vertex to a destination vertex. Even in
non-graph contexts---for example in video games---the more general problem
of finding a path through Euclidian space is often restricted to a graph
for simplicity.

But what if the problem is not able to be solved in this way? What if
we want to find a path between two points through a series of obstacles,
but without foreknowledge of the layout? That is, the only information
that we have is the information that we can currently see. Furthermore,
what if we cannot control our position directly, but can only control
some other parameters? Then the problem becomes much trickier.
\vspace{0.5em}

Consider the following problem:
\vspace{0.5em}

You have a circular spaceship with radius $r$ and mass $m$
in two dimensions located at some point $\mathbf{p}$ equipped with thrusters
on a pair of antipodal points. There
is a known point $\mathbf{q}$ somewhere on the plane, and you want to
get the spaceship there in a reasonable amount of time. Also present
in the space are large polygonal obstacles (e.g., asteroids) 
that must be avoided en route
to $\mathbf{q}$. Although you know where $\mathbf{q}$ is in relation to
$\mathbf{p}$, you don't know where the obstacles are, aside from the
points that you can actually see.

The only way to move the ship is to turn the thrusters up or down. 
For the purposes of this problem, the thrusters are infinitely small
and lie extactly on the circumference of the ship, with thrust being
applied tangentially.
To
move forward, set them to an equal positive force. To move backward,
set them to an equal negative force. To spin around,
the sum should be zero. There is no
way to directly control where in space the ship is at any given time,
or even how fast it is moving; only the acceleration can be controlled
directly, by the thrusters. The thrusters must also be gradually changed
over time; they cannot jump instantly from 10 Newtons to $-10$ Newtons,
for example.
\vspace{0.5em}

In this report, we will attempt to describe a method of solving this
problem using nonlinear optimization methods.

\section{Approach}
Taken as a whole, this problem does not lend itself well to numerical
optimization. The problem itself is inherently non-convex due to the
feasible space having holes in it where the obstacles are, so it is likely
that a solution could not even be found using the usual constrained
optimization methods.

There is, however, a simpler problem that we \emph{can} solve with
constrained optimization, and it happens to be a natural subproblem of
the problem we are really trying to solve. Consider the original
problem, except without any obstacles; we want to compute a trajectory
between two points \emph{within a convex region}. If we can do that,
then we can break the original feasible problem space into convex
regions and solve the subproblem within each region. We can then focus
on solving two separate problems: determining the convex subregions, and 
finding a feasible trajectory within each.

We want to guarantee that the ship doesn't crash, but since we can't see
into the future (at least not beyond the end of the current subproblem),
we need to impose a constraint on the subproblems that
may at first seem drastic:
within each convex subregion, the trajectory from $\mathbf{p}$ to
$\mathbf{q}$ must come to a stop at the end. That doesn't mean, however, that the
ship will be frequently stopping and starting during its journey;
computing such a trajectory only proves that it \emph{can} stop. If we
follow our computed trajectory for only a short amount of time before
throwing it out and solving a new subproblem---hopefully with some new
information each time---we can keep moving closer and closer to the
destination, all the while knowing that we can stop if we must.


%%%%%

\chapter{Finding a Trajectory in a Convex Region}
\section{Power Series Approximation to the Direction}
The direction component of the movement is given by a pair of
coupled differential equations
\begin{equation} \label{eq:orig}
    \begin{aligned}
    d_x'(t) &= -d_y(t)\omega(t)\\
    d_y'(t) &= \phantom{-}d_x(t)\omega(t)
    \end{aligned}
\end{equation}
$\omega(t)$ is the angular velocity at time $t$. Luckily,
$\omega'$ is a constant, so we can approximate
the solution to this differential equation using a simple Maclaurin series.
\begin{equation} \label{eq:series}
    \begin{aligned}
    d_x(t) &= \sum_{n=0}^\infty a_n t^n \\
    d_y(t) &= \sum_{n=0}^\infty b_n t^n
    \end{aligned}
\end{equation}
Substituting Equation \ref{eq:series} into Equation \ref{eq:orig}
(taking the derivative on the left-hand side) gives us
\begin{equation} \label{eq:subst}
    \begin{aligned}
    \sum_{n=0}^\infty n a_n t^{n-1} &=
        -\Bigg[\sum_{n=0}^\infty b_n t^n \Bigg]
        \omega(t) \\
    \sum_{n=0}^\infty n b_n t^{n-1} &=
        \phantom{-}\Bigg[\sum_{n=0}^\infty a_n t^n \Bigg]
        \omega(t)
    \end{aligned}
\end{equation}
Letting $t=0$ in Equation \ref{eq:orig} lets us solve for the constant coefficients. $d_x(0)$ and $d_y(0)$ are given,
so $a_0$ and $b_0$ are fully determined.
\begin{equation} \label{eq:coeff0}
    \begin{aligned}
        a_0 &= d_x(0) \\
        b_0 &= d_y(0)
    \end{aligned}
\end{equation}
Letting $t=0$ in
Equation \ref{eq:subst} lets us solve for the linear coefficients. $\omega(0)$ is given, so $a_1$ and $b_1$ are also
fully determined.
\begin{equation} \label{eq:coeff1}
    \begin{aligned}
    a_1 &= -b_0\omega(0) \\
    b_1 &= \phantom{-}a_0\omega(0)
    \end{aligned}
\end{equation}

At this point, we want to find a general recurrence for \emph{all} of the
coefficients of the Maclaurin series. That way, we can take as many
terms as we need to achieve the desired accuracy without having to
compute and solve for each coefficient by hand.

Since the $k$th coefficient of the Maclaurin series is given by $f^{(k)}(0)/n!$, we need to find a convenient expression for the $k$th derivative of
Equation \ref{eq:subst}.
First we'll compute the first derivative of Equation \ref{eq:subst}.
\begin{equation} \label{eq:diff1}
    \begin{aligned}
    \sum_{n=0}^\infty n(n-1)a_n t^{n-2} &=
        -\Bigg[\sum_{n=0}^\infty nb_n t^{n-1} \Bigg]
            \omega(t)
                - \Bigg[\sum_{n=0}^\infty b_n t^n \Bigg]
                \omega'\\
    \sum_{n=0}^\infty n(n-1)b_n t^{n-2} &=
        \phantom{-}\Bigg[\sum_{n=0}^\infty na_n t^{n-1} \Bigg]
            \omega(t)
                + \Bigg[\sum_{n=0}^\infty a_n t^n \Bigg]
                \omega'\\
    \end{aligned}
\end{equation}
Next, we'll compute the second derivative of Equation \ref{eq:subst}.
\begin{equation} \label{eq:diff2}
    \begin{gathered}
    \shoveleft{\sum_{n=0}^\infty n(n-1)(n-2)a_n t^{n-3} =}\\
        \qquad\qquad-\Bigg[\sum_{n=0}^\infty n(n-1)b_n t^{n-2} \Bigg]
             \omega(t)
                - 2\Bigg[\sum_{n=0}^\infty n b_n t^{n-1} \Bigg]
                \omega'\\
    \shoveleft{\sum_{n=0}^\infty n(n-1)(n-2)b_n t^{n-3} =}\\
        \qquad\qquad\phantom{-}\Bigg[\sum_{n=0}^\infty n(n-1)a_n t^{n-2} \Bigg]
            \omega(t)
                + 2\Bigg[\sum_{n=0}^\infty n a_n t^{n-1} \Bigg]
                \omega'\\
    \end{gathered}
\end{equation}
We can see a pattern emerge if we continue to take derivatives.
We can then represent the $k$th derivative of Equation \ref{eq:subst} as
\begin{equation} \label{eq:diffk}
    \begin{aligned}
    \sum_{n=0}^\infty \frac{n!}{(n-k)!} a_n t^{n-k} =
        -\Bigg[&\sum_{n=0}^\infty \frac{n!}{(n-k+1)!} b_n t^{n-k+1} \Bigg]
             \omega(t)
                \\
                {}-k\Bigg[&\sum_{n=0}^\infty \frac{n!}{(n-k+2)!} b_n t^{n-k+2} \Bigg]
                \omega'\\
    \sum_{n=0}^\infty \frac{n!}{(n-k)!} b_n t^{n-k} =
        \phantom{-}\Bigg[&\sum_{n=0}^\infty \frac{n!}{(n-k+1)!} a_n t^{n-k+1} \Bigg]
             \omega(t)
                \\
                {}+ k\Bigg[&\sum_{n=0}^\infty \frac{n!}{(n-k+2)!} a_n t^{n-k+2} \Bigg]
                \omega'.\\
    \end{aligned}
\end{equation}
Now we can find the $k$th coefficient (for $k > 1$) by
\begin{equation}
    \begin{aligned}
        a_k &= d_x^{(k)}(0)/k! \\
            &= -\Bigg[ \frac{b_{k-1} \omega(0)}{k}  + \frac{b_{k-2} \omega'}{k-1}  \Bigg],\\
        b_k &= d_y^{(k)}(0)/k! \\
            &= \phantom{-} \Bigg[ \frac{a_{k-1} \omega(0)}{k}  + \frac{a_{k-2} \omega'}{k-1}  \Bigg].
    \end{aligned}
\end{equation}
\end{document}